{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684b2975-bfaa-46fb-86ae-a3301949a005",
   "metadata": {},
   "source": [
    "Rule-based matching\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f7171-2542-4455-bff0-d8b3f81e9bb4",
   "metadata": {},
   "source": [
    "In this lesson, we'll take a look at spaCy's matcher, which lets you write rules to find words and phrases in text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897eadf1-d96e-48d9-82ad-a150ae7fa5e9",
   "metadata": {},
   "source": [
    "Compared to regular expressions, the matcher works with Doc and Token objects instead of only strings.\n",
    "\n",
    "It's also more flexible: you can search for texts but also other lexical attributes.\n",
    "\n",
    "You can even write rules that use a model's predictions.\n",
    "\n",
    "For example, find the word \"duck\" only if it's a verb, not a noun.\n",
    "\n",
    "##### Why not just regular expressions?\n",
    "\r",
    "* Match on Doc objects, not just strings\r",
    "* \n",
    "Match on tokens and token attribute\n",
    "* s* \r\n",
    "Use a model's predictio\n",
    "* Example: \"duck\" (verb) vs. \"duck\" (noun)nun)\n",
    "oun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5543ef44-089e-4c5c-b0ba-4cac2c2e2cc6",
   "metadata": {},
   "source": [
    "Match patterns are lists of dictionaries. Each dictionary describes one token. The keys are the names of token attributes, mapped to their expected values.\n",
    "\n",
    "In this example, we're looking for two tokens with the text \"iPhone\" and \"X\".\n",
    "\n",
    "We can also match on other token attributes. Here, we're looking for two tokens whose lowercase forms equal \"iphone\" and \"x\".\n",
    "\n",
    "We can even write patterns using attributes predicted by a model. Here, we're matching a token with the lemma \"buy\", plus a noun. The lemma is the base form, so this pattern would match phrases like \"buying milk\" or \"bought flowers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e0987-0c41-4724-8a12-8ca7efa51fed",
   "metadata": {},
   "source": [
    "Match patterns\n",
    "Lists of dictionaries, one per token\n",
    "\n",
    "* Match exact token texts\n",
    "\n",
    "[{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "* Match lexical attributes\n",
    "* \n",
    "[{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "* Match any token attributes\n",
    "\n",
    "[{\"LEMMA\": \"buy\"}, {\"POS\": \"NOUN\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b045b-01c2-4030-b0cc-baa1c021d0d5",
   "metadata": {},
   "source": [
    "To use a pattern, we first import the matcher from spacy.matcher.\n",
    "\n",
    "We also load a pipeline and create the nlp object.\n",
    "\n",
    "The matcher is initialized with the shared vocabulary, nlp.vocab. You'll learn more about this later – for now, just remember to always pass it in.\n",
    "\n",
    "The matcher.add method lets you add a pattern. The first argument is a unique ID to identify which pattern was matched. The second argument is a list of patterns.\n",
    "\n",
    "To match the pattern on a text, we can call the matcher on any doc.\n",
    "\n",
    "This will return the matches.\n",
    "\n",
    "When you call the matcher on a doc, it returns a list of tuples.\n",
    "\n",
    "Each tuple consists of three values: the match ID, the start index and the end index of the matched span.\n",
    "\n",
    "This means we can iterate over the matches and create a Span object: a slice of the doc at the start and end index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0642ea14-43c3-4c06-bf24-78c6304f46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a pipeline and create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cef1a4-0802-4aea-9113-0cd4d70ec0c9",
   "metadata": {},
   "source": [
    "match_id: hash value of the pattern name\n",
    "\r\n",
    "start: start index of matched spa\n",
    "\n",
    "n\r\n",
    "end: end index of matched span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f6f21-ab14-4ab6-a97e-3971172211ec",
   "metadata": {},
   "source": [
    "##### Matching lexical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcbf13-d287-431d-b449-a66814f16607",
   "metadata": {},
   "source": [
    "Here's an example of a more complex pattern using lexical attributes.\n",
    "\n",
    "We're looking for five tokens:\n",
    "\n",
    "A token consisting of only digits.\n",
    "\n",
    "Three case-insensitive tokens for \"fifa\", \"world\" and \"cup\".\n",
    "\n",
    "And a token that consists of punctuation.\n",
    "\n",
    "The pattern matches the tokens \"2018 FIFA World Cup:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323a897b-7574-4728-b182-6bc99e5662b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "# Initialize the Matcher with the pattern\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"PATTERN\", [pattern])\n",
    "\n",
    "# Sample text\n",
    "text = \"2018 FIFA World Cup: France won!\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find matches\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166b39c-5bfe-40d8-93ff-1238304782d8",
   "metadata": {},
   "source": [
    "In this example, we're looking for two tokens:\n",
    "\n",
    "A verb with the lemma \"love\", followed by a noun.\n",
    "\n",
    "This pattern will match \"loved dogs\" and \"love cats\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c253b384-cacf-4fb9-ae59-1fcecc53bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loved dogs\n",
      "love cats\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "\n",
    "# Initialize the Matcher with the pattern\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"PATTERN2\", [pattern])\n",
    "\n",
    "doc2 = nlp(\"I loved dogs but now I love cats more.\")\n",
    "matches = matcher(doc2)\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc2[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a5f3b-95ee-473b-83d6-aa1c8d9bad8e",
   "metadata": {},
   "source": [
    "Operators and quantifiers let you define how often a token should be matched. They can be added using the \"OP\" key.\n",
    "\n",
    "Here, the \"?\" operator makes the determiner token optional, so it will match a token with the lemma \"buy\", an optional article and a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26dd2741-a7f6-49e6-bcee-c82c26b56479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying apps\n"
     ]
    }
   ],
   "source": [
    "pattern3 = [\n",
    "    {\"LEMMA\": \"buy\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},  # optional: match 0 or 1 times\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Pattern3\", [pattern3])\n",
    "doc3 = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "matches = matcher(doc3)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc3[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e94713-f7c0-4df4-a6f7-c50adb94c2fa",
   "metadata": {},
   "source": [
    "\"OP\" can have one of four values:\n",
    "\n",
    "An \"!\" negates the token, so it's matched 0 times.\n",
    "\n",
    "A \"?\" makes the token optional, and matches it 0 or 1 times.\n",
    "\n",
    "A \"+\" matches a token 1 or more times.\n",
    "\n",
    "And finally, an \"*\" matches 0 or more times.\n",
    "\n",
    "Operators can make your patterns a lot more powerful, but they also add more complexity – so use them wisely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146c95c-7311-478a-bff4-2e35fe8ef34c",
   "metadata": {},
   "source": [
    "Examples\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43386c-bdf4-4e79-beec-60dd13d9ba5e",
   "metadata": {},
   "source": [
    "Let’s try spaCy’s rule-based Matcher. You’ll be using the example from the previous exercise and write a pattern that can match the phrase “iPhone X” in the text.\r\n",
    "* \r\n",
    "Import the Matcher from spacy.matche\n",
    "* Initialize it with the nlp object’s shared vocab.\n",
    "* Create a pattern that matches the \"TEXT\" values of two tokens: \"iPhone\" and \"X\".\n",
    "* Use the matcher.add method to add the pattern to the matcher.\n",
    "* Call the matcher on the doc and store the result in the variable matches.\n",
    "* Iterate over the matches and get the matched span from the start to the end index.r index. index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e121b9d1-82cc-4974-99ae-3ddef50aefea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd427b1-3191-42f0-8804-ad25dfd860f3",
   "metadata": {},
   "source": [
    "You successfully found one match: the tokens at doc[1:3]\n",
    "describing the span for \"iPhone X\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848c0f4-4ab1-4329-87e0-2328854e5256",
   "metadata": {},
   "source": [
    "Part 1\n",
    "Write one pattern that only matches mentions of the full iOS versions: “iOS 7”, “iOS 11” and “iOS 10”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ad6034-dffb-4178-89a2-48972c958abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"After making the iOS update you won't notice a radical system-wide \"\n",
    "    \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n",
    "    \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n",
    "    \"some tweaks once you delve a little deeper.\"\n",
    ")\n",
    "\n",
    "# Write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff08fc8-31e3-4854-931b-e31bc9422252",
   "metadata": {},
   "source": [
    "Part 2\n",
    "Write one pattern that only matches forms of “download” (tokens with the lemma “download”), followed by a token with the part-of-speech tag \"PROPN\" (proper noun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc888719-56aa-4b4a-a684-ab42615dee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: downloaded Fortnite\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
    "    \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
    "    \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
    "    \"I also need to download Winzip?\"\n",
    ")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87d317-2db7-4658-b4f2-71d474fa226a",
   "metadata": {},
   "source": [
    "Part 3\n",
    "Write one pattern that matches adjectives (\"ADJ\") followed by one or two \"NOUN\"s (one noun and one optional noun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32e6a089-7acc-4b4f-81a7-0a47e6bf06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 5\n",
      "Match found: beautiful design\n",
      "Match found: smart search\n",
      "Match found: automatic labels\n",
      "Match found: optional voice\n",
      "Match found: optional voice responses\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"Features of the app include a beautiful design, smart search, automatic \"\n",
    "    \"labels and optional voice responses.\"\n",
    ")\n",
    "\n",
    "# Write a pattern for adjective plus one or two nouns\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef933dd-7566-46f5-8d27-c95becd91f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
