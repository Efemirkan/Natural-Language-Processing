{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec305af9-3969-4c68-9c67-b53265d49223",
   "metadata": {},
   "source": [
    "NLP Trained Pipelines\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85555066-0ff9-4ed7-8b2d-a762d0cc0179",
   "metadata": {},
   "source": [
    "Let's add some more power to the nlp object!\r\n",
    "\r\n",
    "In this lesson, you'll learn about spaCy's trained pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f1f85-a624-4ef9-ab4f-aede50ed624c",
   "metadata": {},
   "source": [
    "Some of the most interesting things you can analyze are context-specific: for example, whether a word is a verb or whether a span of text is a person name.\n",
    "\n",
    "Trained pipeline components have statistical models that enable spaCy to make predictions in context. This usually includes part-of speech tags, syntactic dependencies and named entities.\n",
    "\n",
    "Pipelines are trained on large datasets of labeled example texts.\n",
    "\n",
    "They can be updated with more examples to fine-tune their predictions – for example, to perform better on your specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b75f7-3df4-49f0-9a9d-a8454b6e7e5a",
   "metadata": {},
   "source": [
    "What are trained pipelines?\n",
    "Models that enable spaCy to predict linguistic attributes in context\n",
    "Part-of-speech tags\n",
    "Syntactic dependencies\n",
    "Named entities\n",
    "Trained on labeled example texts\n",
    "Can be updated with more examples to fine-tune predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c5bb6-3b05-4c55-bcdb-cc45540f179d",
   "metadata": {},
   "source": [
    "spaCy provides a number of trained pipeline packages you can download using the spacy download command. For example, the \"en_core_web_sm\" package is a small English pipeline that supports all core capabilities and is trained on web text.\r\n",
    "\r\n",
    "The spacy.load method loads a pipeline package by name and returns an nlp object.\r\n",
    "\r\n",
    "The package provides the binary weights that enable spaCy to make predictions.\r\n",
    "\r\n",
    "It also includes the vocabulary, meta information about the pipeline and the configuration file used to train it. It tells spaCy which language class to use and how to configure the processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16343a8c-f761-4bac-8e77-16d628e6d9c8",
   "metadata": {},
   "source": [
    "Pipeline Packages\n",
    "A package with the label en_core_web_sm\n",
    "\n",
    "Binary weights\n",
    "Vocabulary\n",
    "Meta information\n",
    "Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0acc0b1-46ad-43ea-8335-025bc45e5332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 162.5 kB/s eta 0:01:19\n",
      "     --------------------------------------- 0.0/12.8 MB 186.2 kB/s eta 0:01:09\n",
      "     --------------------------------------- 0.1/12.8 MB 328.2 kB/s eta 0:00:39\n",
      "     --------------------------------------- 0.1/12.8 MB 605.3 kB/s eta 0:00:21\n",
      "      -------------------------------------- 0.2/12.8 MB 784.3 kB/s eta 0:00:17\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.9 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.2/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.0/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.2/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.4/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.6/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.7/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 2.9/12.8 MB 2.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.1/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.0/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.3/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.6/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.8/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.9/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.1/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.0/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.1/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.4/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.7/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.0/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.7/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.8/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.3/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.5/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 3.8 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 3.8 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.4)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734891ab-b968-40be-bb7c-28736e89ca4f",
   "metadata": {},
   "source": [
    "Let's take a look at the model's predictions. In this example, we're using spaCy to predict part-of-speech tags, the word types in context.\r\n",
    "\r\n",
    "First, we load the small English pipeline and receive an nlp object.\r\n",
    "\r\n",
    "Next, we're processing the text \"She ate the pizza\".\r\n",
    "\r\n",
    "For each token in the doc, we can print the text and the .pos_ attribute, the predicted part-of-speech tag.\r\n",
    "\r\n",
    "In spaCy, attributes that return strings usually end with an underscore – attributes without the underscore return an integer ID value.\r\n",
    "\r\n",
    "Here, the model correctly predicted \"ate\" as a verb and \"pizza\" as a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dc90e4-5009-46da-9b70-1236fb38e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the small English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"She ate the pizza\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Print the text and the predicted part-of-speech tag\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1bcc5-f10f-4c8e-9d6c-bc215c54d13c",
   "metadata": {},
   "source": [
    "In addition to the part-of-speech tags, we can also predict how the words are related. For example, whether a word is the subject of the sentence or an object.\n",
    "\n",
    "The .dep_ attribute returns the predicted dependency label.\n",
    "\n",
    "The .head attribute returns the syntactic head token. You can also think of it as the parent token this word is attached to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ada3d9-6648-4b45-81d1-08afc2cbb858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pizza NOUN dobj ate\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83ec4d-8be0-4e01-ac58-51daeb546134",
   "metadata": {},
   "source": [
    "To describe syntactic dependencies, spaCy uses a standardized label scheme. Here's an example of some common labels:\n",
    "\n",
    "The pronoun \"She\" is a nominal subject attached to the verb – in this case, to \"ate\".\n",
    "\n",
    "The noun \"pizza\" is a direct object attached to the verb \"ate\". It is eaten by the subject, \"she\".\n",
    "\n",
    "The determiner \"the\", also known as an article, is attached to the noun \"pizza\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6721d-f793-4d8e-91e3-81344ee11824",
   "metadata": {},
   "source": [
    "##### Predicting Named Entities\n",
    "\n",
    "Named entities are \"real world objects\" that are assigned a name – for example, a person, an organization or a country.\r\n",
    "\r\n",
    "The doc.ents property lets you access the named entities predicted by the named entity recognition model.\r\n",
    "\r\n",
    "It returns an iterator of Span objects, so we can print the entity text and the entity label using the .label_ attribute.\r\n",
    "\r\n",
    "In this case, the model is correctly predicting \"Apple\" as an organization, \"U.K.\" as a geopolitical entity and \"$1 billion\" as money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7f4690-f09b-4b16-88fb-3a66175ca736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "# Process a text\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e8828-5e99-4c05-b860-45dd21e64156",
   "metadata": {},
   "source": [
    "A quick tip: To get definitions for the most common tags and labels, you can use the spacy.explain helper function.\r\n",
    "\r\n",
    "For example, \"GPE\" for geopolitical entity isn't exactly intuitive – but spacy.explain can tell you that it refers to countries, cities and states.\r\n",
    "\r\n",
    "The same works for part-of-speech tags and dependency labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44e14e9-5d8c-43c1-8341-0950d14efdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e6edc0-d064-4357-89a2-4ea17a08e798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"NNP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13fdb325-db22-48a5-a6c7-a8ec346d726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6d0bd-9972-4b62-b5aa-dc5282261c07",
   "metadata": {},
   "source": [
    "Examples\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab558403-c645-4243-a0f0-4084bfeaf1aa",
   "metadata": {},
   "source": [
    "##### The labelled data that the pipeline was trained on.?\n",
    "\n",
    "Trained pipelines allow you to generalize based on a set of training examples. Once they’re trained, they use binary weights to make predictions. That’s why it’s not necessary to ship them with their training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af59091-5b4f-4169-9936-7b4c8ebef00e",
   "metadata": {},
   "source": [
    "##### A config file describing how to create the pipeline.?\n",
    "\n",
    "\n",
    "All saved pipelines include a config.cfg that defines the language to initialize, the pipeline components to load as well as details on how the pipeline was trained and which settings were used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9858c10-a25c-46a5-8dab-8de285468540",
   "metadata": {},
   "source": [
    "##### Binary weights to make statistical predictions.?\n",
    "\n",
    "\n",
    "To predict linguistic annotations like part-of-speech tags, dependency labels or named entities, pipeline packages include binary weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847d3b1-e7bc-4f3b-a9c1-5052c5241910",
   "metadata": {},
   "source": [
    "##### Strings of the pipeline's vocabulary and their hashes.\n",
    "\n",
    "\n",
    "Pipeline packages include a strings.json that stores the entries in the pipeline’s vocabulary and the mapping to hashes. This allows spaCy to only communicate in hashes and look up the corresponding string if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534ba93-e8b3-458b-b8d7-bf9c1ee01059",
   "metadata": {},
   "source": [
    "##### Loading Pipelines\n",
    "The pipelines we’re using in this course are already pre-installed. For more details on spaCy’s trained pipelines and how to install them on your machine, see the documentation.\n",
    "\n",
    "Use spacy.load to load the small English pipeline \"en_core_web_sm\".\n",
    "Process the text and print the document text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc78c0ca-2319-409d-8201-9b13bc04968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the \"en_core_web_sm\" pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21f1ad-2ca8-4901-b62d-343796f8a337",
   "metadata": {},
   "source": [
    "##### Predicting linguistic annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace1d18-5024-462a-9153-9baeee05ba20",
   "metadata": {},
   "source": [
    "You’ll now get to try one of spaCy’s trained pipeline packages and see its predictions in action. Feel free to try it out on your own text! To find out what a tag or label means, you can call spacy.explain in the loop. For example: spacy.explain(\"PROPN\") or spacy.explain(\"GPE\").\n",
    "\n",
    "Part 1\n",
    "\n",
    "* Process the text with the nlp object and create a doc.\n",
    "\r",
    "* \n",
    "For each token, print the token text, the token’s .pos_ (part-of-speech tag) and the token’s .dep_ (dependency label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9851f7c4-90a1-4c46-a422-f3a98cb81919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      nsubj     \n",
      "’s          VERB      ccomp     \n",
      "official    NOUN      acomp     \n",
      ":           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "is          AUX       ROOT      \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c3da23-d484-4d4d-8ee6-c57db496af0c",
   "metadata": {},
   "source": [
    " print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")\n",
    " \n",
    "The provided code snippet utilizes formatted string literals (also known as f-strings) in Python. Let's break down what each part of the f-string does:\n",
    "\n",
    "{token_text:<12}: This part formats the token_text variable with a width of 12 characters and left-aligns the text within that width. If the length of token_text is less than 12 characters, spaces will be added to the right to fill the remaining space.\n",
    "{token_pos:<10}: Similar to the first part, this formats the token_pos variable with a width of 10 characters and left-aligns the text within that width.\n",
    "{token_dep:<10}: Again, this formats the token_dep variable with a width of 10 characters and left-aligns the text within that width.\n",
    "Overall, this formatting ensures that each part (token_text, token_pos, and token_dep) of the printed output is given a specific width, making it easier to read and understand the output, especially when dealing with tabular data or fixed-width text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8e0c0-4095-48ec-927b-0bba9c644449",
   "metadata": {},
   "source": [
    "Part 2\n",
    "\n",
    "* Process the text and create a doc object.\n",
    "* Iterate over the doc.ents and print the entity text and label_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ebc6140-3b33-41ab-b158-959aa332acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "first ORDINAL\n",
      "U.S. GPE\n",
      "$1 trillion MONEY\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f92076-b786-4720-965d-4b9914b7d406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"first\", \"second\", etc.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORDINAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238ed68-a560-4961-bd90-f21bc4e12b1a",
   "metadata": {},
   "source": [
    "##### Predicting named entities in context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8c682-3b7d-44a7-96e9-c13c15aa595f",
   "metadata": {},
   "source": [
    "Models are statistical and not always right. Whether their predictions are correct depends on the training data and the text you’re processing. Let’s take a look at an example.\n",
    "\n",
    "* Process the text with the nlp object.\n",
    "* Iterate over the entities and print the entity text and label.\n",
    "* Looks like the model didn’t predict “iPhone X”. Create a span for those tokens manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a2b626e-43c2-4f0a-b037-db20d409530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0295577-34a3-48e9-b305-b6a3acf19603",
   "metadata": {},
   "source": [
    "you don't always have to do this manually. In the\n",
    "next exercise, you'll learn about spaCy's rule-based matcher, which can help you\n",
    "find certain words and phrases in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee2642-f08d-4445-98db-2c4f34dd55b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
